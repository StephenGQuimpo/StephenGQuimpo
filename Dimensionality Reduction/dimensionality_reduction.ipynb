{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84248607 0.14631839]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.26203346  0.42067648]\n",
      " [-0.08001485 -0.35272239]\n",
      " [ 1.17545763  0.36085729]\n",
      " [ 0.89305601 -0.30862856]\n",
      " [ 0.73016287 -0.25404049]]\n",
      "[[ 1.26203346  0.42067648]\n",
      " [-0.08001485 -0.35272239]\n",
      " [ 1.17545763  0.36085729]\n",
      " [ 0.89305601 -0.30862856]\n",
      " [ 0.73016287 -0.25404049]]\n"
     ]
    }
   ],
   "source": [
    "print(X2D[:5])\n",
    "print(x_reduced[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca = PCA(n_components = 154)\n",
    "X_mnist_reduced = pca.fit_transform(X_mnist)\n",
    "X_mnist_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)\n",
    "for X_batch in np.array_split(X_mnist, n_batches):\n",
    "    print(\".\", end=\"\")\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "\n",
    "X_mnist_reduced = inc_pca.transform(X_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_reduced[:10, 0], X_reduced[:10, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1) We want to visualise the data in 2 or 3 dimensions, or we want to speed up training considerably when there are very large number of features. Drawbacks include a slight loss of information, and also time taken to reduce vary between dimensionality reduction techniques.\n",
    "\n",
    "2) This is the problem that high-dimensional datasets are hard to visualise and to understand the behaviours of the data in a sparse hyperspace. More dimensions also increases the risk of overfitting the training data.\n",
    "\n",
    "3) Yes, we can use the `inverse_transform()` method to revert back to the original data, but there will be some loss of quality or information.\n",
    "\n",
    "4) We can do it, but it may be better to use kPCA or LLE to capture nonlinearity such as manifolds in the data.\n",
    "\n",
    "5) It depends on the dataset, but we can estimate about `m / 5` so roughly 200 dimensions.\n",
    "\n",
    "6) Vanilla PCA: We can use this when the dataset can fit in memory and is not highly nonlinear\n",
    "\n",
    "Incremental PCA: We use this to use out-of-core for training sets too large to fit in memory to as part of online learning systems\n",
    "\n",
    "Randomised PCA: We use this to speed up the process of dimensionality reduction by approximating the first d PCs\n",
    "\n",
    "Kernel PCA: When we have complex nonlinear relationships\n",
    "\n",
    "7) We can compare the reconstruction error or use a supervised method by training a classifier to check the performance when using the reduced dimensions training data versus the full data.\n",
    "\n",
    "8) Yes, If we have complex nonlinearity, we can use kPCA or LLE to reduce dimensions with 95% explained variance, and then use t-SNE to visualise the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1)\n",
    "    mnist.target = mnist.target.astype(np.int64)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist.data[:60000], mnist.target[:60000]\n",
    "X_test, y_test = mnist.data[60000:], mnist.target[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 8.028\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "forest_clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Time:', round(end - start, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9492\n"
     ]
    }
   ],
   "source": [
    "print(forest_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 22.898\n"
     ]
    }
   ],
   "source": [
    "forest_clf2 = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "start = time.time()\n",
    "forest_clf2.fit(X_train_reduced, y_train)\n",
    "end = time.time()\n",
    "print('Time:', round(end - start, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9009\n"
     ]
    }
   ],
   "source": [
    "print(forest_clf2.score(X_test_reduced, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 42.839s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "t0 = time.time()\n",
    "log_clf.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print('Time {:.3f}s'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9255"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 9.316s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "log_clf2 = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "t0 = time.time()\n",
    "log_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()\n",
    "print('Time {:.3f}s'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9201"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf2.score(X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA then t-SNE in a pipeline\n",
    "\n",
    "`pca_tsne = Pipeline([\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"tsne\", TSNE(n_components=2, random_state=42)),\n",
    "])`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
